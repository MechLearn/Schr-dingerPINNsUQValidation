{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821b7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 12:51:11.776501: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-08 12:51:11.819516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-08 12:51:12.816997: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Política actual: <DTypePolicy \"mixed_float16\">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759945873.812006   16346 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1607 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-10-08 12:51:14.562046: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PINN] n=1 ep=1 | LPDE=2.114e-02 Lnorm=9.998e-01 L=4.001e+01 ∫|ψ|²≈0.000\n",
      "[PINN] n=1 ep=800 | LPDE=1.938e-03 Lnorm=5.631e-09 L=1.938e-03 ∫|ψ|²≈1.000\n",
      "[PINN] n=1 ep=1600 | LPDE=1.295e-03 Lnorm=1.005e-08 L=1.295e-03 ∫|ψ|²≈1.000\n",
      "[PINN] n=1 ep=2400 | LPDE=7.278e-04 Lnorm=5.807e-08 L=7.284e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=1 ep=3200 | LPDE=3.642e-04 Lnorm=3.883e-08 L=3.646e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=1 ep=4000 | LPDE=1.882e-04 Lnorm=1.720e-10 L=1.882e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=2 ep=1 | LPDE=1.091e+00 Lnorm=9.970e-01 L=4.097e+01 ∫|ψ|²≈0.002\n",
      "[PINN] n=2 ep=1000 | LPDE=5.681e-04 Lnorm=3.050e-08 L=5.693e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=2 ep=2000 | LPDE=2.131e-04 Lnorm=9.956e-09 L=2.132e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=2 ep=3000 | LPDE=1.447e-04 Lnorm=7.982e-10 L=1.447e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=2 ep=4000 | LPDE=6.218e-05 Lnorm=1.541e-08 L=6.241e-05 ∫|ψ|²≈1.000\n",
      "[PINN] n=2 ep=5000 | LPDE=3.533e-05 Lnorm=3.553e-11 L=3.533e-05 ∫|ψ|²≈1.000\n",
      "[PINN] n=2 ep=6000 | LPDE=2.304e-05 Lnorm=3.624e-11 L=2.304e-05 ∫|ψ|²≈1.000\n",
      "[PINN] n=3 ep=1 | LPDE=1.994e+00 Lnorm=9.975e-01 L=3.013e+02 ∫|ψ|²≈0.001\n",
      "[PINN] n=3 ep=1500 | LPDE=3.780e-03 Lnorm=6.389e-06 L=5.697e-03 ∫|ψ|²≈1.003\n",
      "[PINN] n=3 ep=3000 | LPDE=1.239e-03 Lnorm=5.768e-06 L=1.701e-03 ∫|ψ|²≈1.002\n",
      "[PINN] n=3 ep=4500 | LPDE=1.121e-03 Lnorm=2.205e-06 L=1.298e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=3 ep=6000 | LPDE=1.385e-04 Lnorm=1.106e-09 L=1.386e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=3 ep=7500 | LPDE=1.403e-04 Lnorm=4.283e-09 L=1.406e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=3 ep=9000 | LPDE=1.378e-04 Lnorm=1.701e-09 L=1.380e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=4 ep=1 | LPDE=2.622e+00 Lnorm=9.982e-01 L=3.021e+02 ∫|ψ|²≈0.001\n",
      "[PINN] n=4 ep=2500 | LPDE=1.820e-02 Lnorm=7.007e-06 L=2.030e-02 ∫|ψ|²≈1.003\n",
      "[PINN] n=4 ep=5000 | LPDE=7.348e-03 Lnorm=1.549e-05 L=8.588e-03 ∫|ψ|²≈0.996\n",
      "[PINN] n=4 ep=7500 | LPDE=1.471e-03 Lnorm=1.485e-06 L=1.590e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=4 ep=10000 | LPDE=1.373e-03 Lnorm=1.513e-06 L=1.494e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=4 ep=12500 | LPDE=3.157e-04 Lnorm=5.684e-12 L=3.157e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=4 ep=15000 | LPDE=2.686e-04 Lnorm=7.781e-10 L=2.687e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=5 ep=1 | LPDE=4.891e-03 Lnorm=1.000e+00 L=3.000e+02 ∫|ψ|²≈0.000\n",
      "[PINN] n=5 ep=2500 | LPDE=7.446e-03 Lnorm=4.132e-06 L=8.686e-03 ∫|ψ|²≈0.998\n",
      "[PINN] n=5 ep=5000 | LPDE=4.486e-03 Lnorm=6.745e-06 L=5.026e-03 ∫|ψ|²≈0.997\n",
      "[PINN] n=5 ep=7500 | LPDE=6.594e-03 Lnorm=4.463e-06 L=6.951e-03 ∫|ψ|²≈1.002\n",
      "[PINN] n=5 ep=10000 | LPDE=1.124e-03 Lnorm=6.205e-07 L=1.173e-03 ∫|ψ|²≈0.999\n",
      "[PINN] n=5 ep=12500 | LPDE=3.166e-04 Lnorm=7.490e-09 L=3.172e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=5 ep=15000 | LPDE=2.950e-04 Lnorm=5.628e-10 L=2.950e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=6 ep=1 | LPDE=8.888e-02 Lnorm=1.000e+00 L=3.001e+02 ∫|ψ|²≈0.000\n",
      "[PINN] n=6 ep=2500 | LPDE=3.338e-03 Lnorm=1.770e-06 L=3.868e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=6 ep=5000 | LPDE=2.561e-03 Lnorm=1.380e-06 L=2.671e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=6 ep=7500 | LPDE=1.594e-03 Lnorm=5.701e-07 L=1.639e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=6 ep=10000 | LPDE=1.066e-03 Lnorm=3.644e-07 L=1.095e-03 ∫|ψ|²≈1.001\n",
      "[PINN] n=6 ep=12500 | LPDE=5.155e-04 Lnorm=8.391e-08 L=5.222e-04 ∫|ψ|²≈1.000\n",
      "[PINN] n=6 ep=15000 | LPDE=3.567e-04 Lnorm=4.083e-09 L=3.570e-04 ∫|ψ|²≈1.000\n",
      "[OK] Guardado CSV: /home/david/Schr-dingerPINNsUQValidation/PrimeraFase/ValidacionPozoInfinito/DiferenciasFinitas/ResultadosD/comp/resumen_pinn_vs_df.csv\n",
      "[OK] Figuras por modo: /home/david/Schr-dingerPINNsUQValidation/PrimeraFase/ValidacionPozoInfinito/DiferenciasFinitas/ResultadosD/comp\n",
      "[[1,\n",
      "  9.869604401089358,\n",
      "  9.869591685158948,\n",
      "  0.00010041311938839941,\n",
      "  5.799180249170713e-07,\n",
      "  0.00010041106954682855,\n",
      "  0.9999083876609802,\n",
      "  1.0],\n",
      " [2,\n",
      "  39.47841760435743,\n",
      "  39.47821416017628,\n",
      "  8.441168459984665e-05,\n",
      "  2.3079651536373625e-06,\n",
      "  8.44882778719652e-05,\n",
      "  1.000004768371582,\n",
      "  1.0],\n",
      " [3,\n",
      "  88.82643960980423,\n",
      "  88.82540967913938,\n",
      "  9.618394715945938e-05,\n",
      "  4.867468866005013e-06,\n",
      "  9.636993022034765e-05,\n",
      "  1.0000653266906738,\n",
      "  1.0]]\n",
      "\n",
      "Salidas en:\n",
      "  - PINN:         /home/david/Schr-dingerPINNsUQValidation/PrimeraFase/ValidacionPozoInfinito/DiferenciasFinitas/ResultadosD/pinn\n",
      "  - DF:           /home/david/Schr-dingerPINNsUQValidation/PrimeraFase/ValidacionPozoInfinito/DiferenciasFinitas/ResultadosD/fd\n",
      "  - Comparación:  /home/david/Schr-dingerPINNsUQValidation/PrimeraFase/ValidacionPozoInfinito/DiferenciasFinitas/ResultadosD/comp\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Pozo infinito 1D — PINN vs Diferencias Finitas (DF)\n",
    "# Validación con E_n = (n*pi)^2, comparación y caché de resultados.\n",
    "# TensorFlow 2.16+ / Keras 3\n",
    "# ============================================\n",
    "\n",
    "import os, math, csv, random, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, ops as K\n",
    "\n",
    "# ============ RUTA BASE ============\n",
    "BASE_DIR = \"/home/david/Schr-dingerPINNsUQValidation/PrimeraFase/ValidacionPozoInfinito/DiferenciasFinitas/ResultadosD\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "def path(*args, is_dir=False):\n",
    "    \"\"\"Une rutas relativas dentro de BASE_DIR y crea el directorio padre.\"\"\"\n",
    "    p = os.path.join(BASE_DIR, *args)\n",
    "    d = p if is_dir else os.path.dirname(p)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "# ============ SEMILLAS Y GPU ============\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Memory growth\n",
    "for g in tf.config.list_physical_devices(\"GPU\"):\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# (Opcional) Mixed precision para Tensor Cores\n",
    "USE_MIXED_PRECISION = True\n",
    "if USE_MIXED_PRECISION:\n",
    "    keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "print(\"Política actual:\", keras.mixed_precision.global_policy())\n",
    "\n",
    "# ============ UTILIDADES ============\n",
    "def trapz_np(y, x):\n",
    "    y = y.astype(np.float32, copy=False)\n",
    "    return float(np.trapezoid(y, x=x))\n",
    "\n",
    "def l2_rel(y_true, y_pred):\n",
    "    num = np.linalg.norm(y_true - y_pred)\n",
    "    den = np.linalg.norm(y_true) + 1e-12\n",
    "    return float(num / den)\n",
    "\n",
    "def normalize_to_one(xs, psi):\n",
    "    \"\"\"Normaliza psi para que ∫|psi|^2 dx = 1 en [min(xs), max(xs)].\"\"\"\n",
    "    val = trapz_np(np.abs(psi)**2, xs)\n",
    "    if val <= 0:\n",
    "        return psi, 0.0\n",
    "    psi2 = psi / np.sqrt(val)\n",
    "    return psi2, 1.0\n",
    "\n",
    "# ============ ANALÍTICA ============\n",
    "def analytic_psi(n, xs):\n",
    "    return np.sqrt(2.0) * np.sin(n * math.pi * xs)\n",
    "\n",
    "def analytic_E(n):\n",
    "    return (n * math.pi)**2\n",
    "\n",
    "# ============ DIFERENCIAS FINITAS ============\n",
    "def fd_solve(n_modes=6, N=800):\n",
    "    \"\"\"\n",
    "    Resuelve -psi'' = E psi en (0,1), Dirichlet psi(0)=psi(1)=0,\n",
    "    con m = N-2 puntos interiores, h = 1/(N-1).\n",
    "    Devuelve:\n",
    "      xs_fd: m+2 puntos (incluye 0 y 1), psi_fd[k], E_fd[k] para k=1..n_modes\n",
    "    \"\"\"\n",
    "    # Malla con extremos incluidos (0..1). Usamos interior para el sistema.\n",
    "    xs = np.linspace(0.0, 1.0, N, dtype=np.float64)\n",
    "    h = xs[1] - xs[0]\n",
    "    m = N - 2  # puntos interiores\n",
    "    # Matriz tridiagonal del -d2/dx2 con Dirichlet (interior)\n",
    "    main = (2.0 / h**2) * np.ones(m)\n",
    "    off  = (-1.0 / h**2) * np.ones(m-1)\n",
    "    # Construcción densa (N pequeño). Para N grandes, usar scipy.sparse.\n",
    "    A = np.diag(main) + np.diag(off, k=1) + np.diag(off, k=-1)\n",
    "    # Autovalores y autovectores\n",
    "    w, V = np.linalg.eigh(A)  # w ascendente\n",
    "    # Seleccionamos los primeros n_modes\n",
    "    nm = min(n_modes, m)\n",
    "    E_fd = w[:nm].astype(float)  # ~ (n*pi)^2\n",
    "    psi_fd = []\n",
    "    for k in range(nm):\n",
    "        v = V[:, k]\n",
    "        # Insertar ceros en extremos para cumplir Dirichlet\n",
    "        psi_full = np.zeros(N, dtype=float)\n",
    "        psi_full[1:-1] = v\n",
    "        # Normalizar a ∫|psi|^2 dx = 1\n",
    "        psi_full, _ = normalize_to_one(xs, psi_full)\n",
    "        # Alineación de signo (consistencia con sin positivo cerca de inicio)\n",
    "        sgn = np.sign(np.dot(psi_full, analytic_psi(k+1, xs)))\n",
    "        if sgn == 0: sgn = 1.0\n",
    "        psi_full *= sgn\n",
    "        psi_fd.append(psi_full.astype(float))\n",
    "    return xs.astype(float), psi_fd, E_fd\n",
    "\n",
    "# ============ PINN ============\n",
    "class Sine(layers.Layer):\n",
    "    def call(self, x):\n",
    "        return K.sin(x)\n",
    "\n",
    "def trig_nodal_factor(x, n: int):\n",
    "    eps = K.cast(1e-12, x.dtype)\n",
    "    s1  = K.sin(math.pi * x)\n",
    "    sn  = K.sin(n * math.pi * x)\n",
    "    ratio = sn / (s1 + eps)\n",
    "    n_cast = K.cast(n, x.dtype)\n",
    "    return K.where(K.abs(s1) < 1e-6, n_cast, ratio)\n",
    "\n",
    "def make_net(n=1, hidden=64, use_sine=True):\n",
    "    x_in = keras.Input(shape=(1,), dtype=\"float32\")\n",
    "    if use_sine:\n",
    "        z = layers.Dense(hidden, activation=None,\n",
    "                         kernel_initializer=\"glorot_uniform\",\n",
    "                         bias_initializer=\"zeros\")(x_in)\n",
    "        z = Sine()(z)\n",
    "        z = layers.Dense(hidden, activation=None,\n",
    "                         kernel_initializer=\"glorot_uniform\",\n",
    "                         bias_initializer=\"zeros\")(z)\n",
    "        z = Sine()(z)\n",
    "    else:\n",
    "        z = layers.Dense(hidden, activation=\"tanh\",\n",
    "                         kernel_initializer=\"glorot_uniform\",\n",
    "                         bias_initializer=\"zeros\")(x_in)\n",
    "        z = layers.Dense(hidden, activation=\"tanh\",\n",
    "                         kernel_initializer=\"glorot_uniform\",\n",
    "                         bias_initializer=\"zeros\")(z)\n",
    "    out = layers.Dense(1, activation=None,\n",
    "                       kernel_initializer=\"glorot_uniform\",\n",
    "                       bias_initializer=\"zeros\",\n",
    "                       dtype=\"float32\")(z)\n",
    "    F = trig_nodal_factor(x_in, n)\n",
    "    psi = K.multiply(x_in, (1.0 - x_in))\n",
    "    psi = K.multiply(psi, F)\n",
    "    psi = K.multiply(psi, out)\n",
    "    return keras.Model(inputs=x_in, outputs=psi)\n",
    "\n",
    "def second_derivative(model, x):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    x = tf.reshape(x, (-1,1))\n",
    "    with tf.GradientTape(persistent=True) as t2:\n",
    "        t2.watch(x)\n",
    "        with tf.GradientTape() as t1:\n",
    "            t1.watch(x)\n",
    "            psi = model(x)\n",
    "        psi_x = t1.gradient(psi, x)\n",
    "    psi_xx = t2.gradient(psi_x, x)\n",
    "    del t2\n",
    "    return psi, psi_xx\n",
    "\n",
    "@tf.function\n",
    "def compute_losses(net, x_batch, E, lam):\n",
    "    psi, psi_xx = second_derivative(net, x_batch)\n",
    "    res = psi_xx + E * psi\n",
    "    LPDE = tf.reduce_mean(tf.square(res))\n",
    "    psi2 = tf.squeeze(tf.square(psi), axis=1)\n",
    "    xb   = tf.squeeze(tf.convert_to_tensor(x_batch), axis=1)\n",
    "    dx   = xb[1:] - xb[:-1]\n",
    "    integral = tf.reduce_sum(0.5*(psi2[1:] + psi2[:-1]) * dx)\n",
    "    Lnorm = tf.square(integral - 1.0)\n",
    "    L = LPDE + lam * Lnorm\n",
    "    return L, LPDE, Lnorm, integral\n",
    "\n",
    "def run_one_mode_pinn(n, force=False):\n",
    "    \"\"\"\n",
    "    Entrena (o carga de caché) la PINN para modo n, con E fija.\n",
    "    Guarda/lee de BASE_DIR/pinn/n{n}.npz y figuras en BASE_DIR/pinn/.\n",
    "    \"\"\"\n",
    "    cache_npz = path(\"pinn\", f\"n{n}.npz\")\n",
    "    fig_loss  = path(\"pinn\", f\"loss_n{n}.png\")\n",
    "    fig_modo  = path(\"pinn\", f\"modo_n{n}.png\")\n",
    "\n",
    "    # Si hay caché y no se fuerza, cargar y salir\n",
    "    if (not force) and os.path.isfile(cache_npz):\n",
    "        data = np.load(cache_npz, allow_pickle=True)\n",
    "        return {\n",
    "            \"n\": int(data[\"n\"]),\n",
    "            \"xs\": data[\"xs\"],\n",
    "            \"psi_pred\": data[\"psi_pred\"],\n",
    "            \"psi_exact\": data[\"psi_exact\"],\n",
    "            \"E\": float(data[\"E\"]),\n",
    "            \"L2\": float(data[\"L2\"]),\n",
    "            \"integral\": float(data[\"integral\"]),\n",
    "            \"loss_path\": fig_loss,\n",
    "            \"fig_path\": fig_modo,\n",
    "        }\n",
    "\n",
    "    # Hiperparámetros heurísticos por n\n",
    "    E = np.float32((n * math.pi)**2)\n",
    "    USE_SINE = True if n >= 3 else False\n",
    "    HIDDEN   = 128 if n >= 3 else 64\n",
    "    N_col    = max(1024, 2048*n)\n",
    "    EPOCHS   = 15000 if n >= 4 else (9000 if n==3 else (6000 if n==2 else 4000))\n",
    "    LR0      = 3e-4  if n >= 4 else (5e-4 if n==3 else (7e-4 if n==2 else 1e-3))\n",
    "    lam_hi, lam_lo = (300.0, 80.0) if n >= 3 else (40.0, 15.0 if n==2 else 10.0)\n",
    "\n",
    "    net = make_net(n=n, hidden=HIDDEN, use_sine=USE_SINE)\n",
    "    x_col = np.linspace(0,1,N_col, dtype=np.float32).reshape(-1,1)\n",
    "    x_batch = tf.constant(x_col)\n",
    "\n",
    "    lr_sched = keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=LR0, decay_steps=EPOCHS,\n",
    "        end_learning_rate=LR0*0.1, power=1.0\n",
    "    )\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_sched, clipnorm=1.0)\n",
    "\n",
    "    loss_total, loss_pde, loss_norm = [], [], []\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        lam = lam_hi if ep < EPOCHS//3 else lam_lo\n",
    "        with tf.GradientTape() as tape:\n",
    "            L, LPDE, Lnorm, integral = compute_losses(net, x_batch, E, lam)\n",
    "        grads = tape.gradient(L, net.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, net.trainable_variables))\n",
    "        loss_total.append(float(L)); loss_pde.append(float(LPDE)); loss_norm.append(float(Lnorm))\n",
    "        if ep % max(800, EPOCHS//6) == 0 or ep == 1:\n",
    "            tf.print(f\"[PINN] n={n} ep={ep} | LPDE={LPDE:.3e} Lnorm={Lnorm:.3e} L={L:.3e} ∫|ψ|²≈{integral:.3f}\")\n",
    "\n",
    "    # Curva de pérdida\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.semilogy(loss_total, label=\"Total\")\n",
    "    plt.semilogy(loss_pde,   label=r\"$\\mathcal{L}_{PDE}$\")\n",
    "    plt.semilogy(loss_norm,  label=r\"$\\mathcal{L}_{norm}$\")\n",
    "    plt.xlabel(\"Épocas\"); plt.ylabel(\"Pérdida\"); plt.title(f\"PINN — Curva de pérdida (n={n})\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(fig_loss, dpi=160); plt.close()\n",
    "\n",
    "    # Evaluación fina\n",
    "    xs = np.linspace(0,1,2000, dtype=np.float32).reshape(-1,1)\n",
    "    psi_pred  = net(xs).numpy().squeeze().astype(np.float64)\n",
    "    psi_exact = analytic_psi(n, xs.squeeze()).astype(np.float64)\n",
    "    dot = float(np.dot(psi_pred, psi_exact))\n",
    "    sgn = np.sign(dot);  sgn = 1.0 if sgn == 0 else sgn\n",
    "    psi_pred *= sgn\n",
    "    L2 = float(np.sqrt(np.mean((psi_pred-psi_exact)**2)))\n",
    "    integ = trapz_np(psi_pred**2, x=xs.squeeze())\n",
    "\n",
    "    # Figura PINN vs exacta\n",
    "    plt.figure(figsize=(7.2,4.2))\n",
    "    plt.plot(xs.squeeze(), psi_pred,  label=f\"PINN ψ{n}\")\n",
    "    plt.plot(xs.squeeze(), psi_exact, \"--\", color=\"gray\", label=f\"Exacta ψ{n}\")\n",
    "    plt.title(f\"PINN vs Exacta — n={n} | E={(n*math.pi)**2:.2f} | L2={L2:.2e}\")\n",
    "    plt.xlabel(\"x\"); plt.ylabel(\"ψ\"); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(fig_modo, dpi=170); plt.close()\n",
    "\n",
    "    # Guardar caché\n",
    "    np.savez(cache_npz, n=n, xs=xs.squeeze().astype(float),\n",
    "             psi_pred=psi_pred.astype(float), psi_exact=psi_exact.astype(float),\n",
    "             E=float(E), L2=float(L2), integral=float(integ))\n",
    "\n",
    "    return {\n",
    "        \"n\": n, \"xs\": xs.squeeze(), \"psi_pred\": psi_pred, \"psi_exact\": psi_exact,\n",
    "        \"E\": float(E), \"L2\": float(L2), \"integral\": float(integ),\n",
    "        \"loss_path\": fig_loss, \"fig_path\": fig_modo\n",
    "    }\n",
    "\n",
    "# ============ COMPARACIÓN PINN vs DF ============\n",
    "def compare_pinn_fd(n_list, N_fd=800, force_pinn=False):\n",
    "    # DF una sola vez (malla fija para todos)\n",
    "    xs_fd, psi_fd_list, E_fd = fd_solve(n_modes=max(n_list), N=N_fd)\n",
    "\n",
    "    # Export DF\n",
    "    for idx, n in enumerate(range(1, max(n_list)+1), start=1):\n",
    "        np.savez(path(\"fd\", f\"n{n}.npz\"),\n",
    "                 xs=xs_fd.astype(float),\n",
    "                 psi=psi_fd_list[idx-1].astype(float),\n",
    "                 E=float(E_fd[idx-1]))\n",
    "    # Tabla de resumen\n",
    "    summary_rows = []\n",
    "\n",
    "    # Por cada n: correr/cargar PINN y comparar\n",
    "    for n in n_list:\n",
    "        pinn = run_one_mode_pinn(n, force=force_pinn)\n",
    "\n",
    "        # Interpolar DF a la malla fina de PINN (o al revés)\n",
    "        from numpy import interp\n",
    "        xs_p = pinn[\"xs\"]\n",
    "        psi_fd = interp(xs_p, xs_fd, psi_fd_list[n-1]).astype(float)\n",
    "        psi_fd, _ = normalize_to_one(xs_p, psi_fd)\n",
    "\n",
    "        psi_ex = analytic_psi(n, xs_p).astype(float)\n",
    "\n",
    "        # Errores L2 absolutos (no relativos) sobre malla xs_p\n",
    "        L2_pinn_exact = float(np.sqrt(np.mean((pinn[\"psi_pred\"] - psi_ex)**2)))\n",
    "        L2_fd_exact   = float(np.sqrt(np.mean((psi_fd - psi_ex)**2)))\n",
    "        L2_pinn_fd    = float(np.sqrt(np.mean((pinn[\"psi_pred\"] - psi_fd)**2)))\n",
    "\n",
    "        # Normalizaciones\n",
    "        norm_pinn = trapz_np(np.abs(pinn[\"psi_pred\"])**2, xs_p)\n",
    "        norm_fd   = trapz_np(np.abs(psi_fd)**2, xs_p)\n",
    "\n",
    "        # Energies\n",
    "        E_an = analytic_E(n)\n",
    "        E_df = float(E_fd[n-1])\n",
    "\n",
    "        summary_rows.append([\n",
    "            n, E_an, E_df, L2_pinn_exact, L2_fd_exact, L2_pinn_fd, norm_pinn, norm_fd\n",
    "        ])\n",
    "\n",
    "        # Figura comparativa PINN vs DF vs Exacta\n",
    "        plt.figure(figsize=(7.6,4.6))\n",
    "        plt.plot(xs_p, psi_ex,  \"--\", color=\"gray\", label=\"Exacta\")\n",
    "        plt.plot(xs_p, pinn[\"psi_pred\"],  \"-\",  label=\"PINN\")\n",
    "        plt.plot(xs_p, psi_fd, \":\",  label=\"DF (interp.)\")\n",
    "        plt.title(f\"n={n} | E_an={(E_an):.2f} | E_df={(E_df):.2f}\\n\"\n",
    "                  f\"L2(PINN,Exact)={L2_pinn_exact:.2e} | L2(DF,Exact)={L2_fd_exact:.2e} | L2(PINN,DF)={L2_pinn_fd:.2e}\")\n",
    "        plt.xlabel(\"x\"); plt.ylabel(\"ψ\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path(\"comp\", f\"comp_n{n}.png\"), dpi=180)\n",
    "        plt.close()\n",
    "\n",
    "    # Guardar CSV resumen\n",
    "    csv_path = path(\"comp\", \"resumen_pinn_vs_df.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"n\", \"E_analitica\", \"E_df\",\n",
    "                    \"L2(PINN,Exacta)\", \"L2(DF,Exacta)\", \"L2(PINN,DF)\",\n",
    "                    \"Norm(PINN)\", \"Norm(DF)\"])\n",
    "        for row in summary_rows:\n",
    "            w.writerow(row)\n",
    "\n",
    "    # Figura global de errores vs n\n",
    "    ns = [r[0] for r in summary_rows]\n",
    "    L2_pinn_exact = [r[3] for r in summary_rows]\n",
    "    L2_fd_exact   = [r[4] for r in summary_rows]\n",
    "    L2_pinn_fd    = [r[5] for r in summary_rows]\n",
    "\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    plt.plot(ns, L2_pinn_exact, \"o-\", label=\"L2(PINN,Exacta)\")\n",
    "    plt.plot(ns, L2_fd_exact,   \"s--\", label=\"L2(DF,Exacta)\")\n",
    "    plt.plot(ns, L2_pinn_fd,    \"d-.\", label=\"L2(PINN,DF)\")\n",
    "    plt.yscale(\"log\"); plt.xlabel(\"Modo n\"); plt.ylabel(\"Error L2 (log)\")\n",
    "    plt.title(\"Errores vs n — PINN vs DF vs Analítica\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path(\"comp\", \"errores_globales.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[OK] Guardado CSV: {csv_path}\")\n",
    "    print(f\"[OK] Figuras por modo: {path('comp', is_dir=True)}\")\n",
    "    return summary_rows\n",
    "\n",
    "# ============ EJECUCIÓN RÁPIDA ============\n",
    "# Configura aquí cuántos modos deseas y si quieres forzar re-entrenamiento.\n",
    "N_MAX = 6\n",
    "FORCE_TRAIN = False    # True para reentrenar PINN ignorando caché\n",
    "N_FD_GRID = 800        # puntos totales (incluye extremos) para DF\n",
    "\n",
    "rows = compare_pinn_fd(list(range(1, N_MAX+1)), N_fd=N_FD_GRID, force_pinn=FORCE_TRAIN)\n",
    "\n",
    "# Muestra breve del resumen\n",
    "from pprint import pprint\n",
    "pprint(rows[:3])\n",
    "print(\"\\nSalidas en:\")\n",
    "print(\"  - PINN:        \", path('pinn', is_dir=True))\n",
    "print(\"  - DF:          \", path('fd', is_dir=True))\n",
    "print(\"  - Comparación: \", path('comp', is_dir=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
